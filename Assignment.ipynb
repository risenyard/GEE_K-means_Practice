{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Exercise #2\n",
    "\n",
    "In this graded group exercise, you will use the **GEE Python API** and the **geemap Python package** to:\n",
    "\n",
    "- Retrieve a collection of satellite images over a study area\n",
    "- Create a composite image and visualize it\n",
    "- Apply a simple unsupervised machine learning algorithm (e.g., k-means) for clustering the study area\n",
    "- Analyze the clustering results given a set of reference points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "### 1. Define a case study area \n",
    "*The size of bounding box covering the study area should be large enough (e.g., few hundred kilometers).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the process, the initialization of the API needs to be done.\n",
    "- Two packages are needed: `ee` and `geemap`\n",
    "- The authentication line is necessary to access the resources in Google Earth Engine. And it should be run at first and follow the instructions. Then the Python environment knows the authentication and it needn't be executed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Earth Engine has initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import sys\n",
    "\n",
    "#   Please run this just once to get access to the resources in GEE\n",
    "#   ee.Authenticate()\n",
    "\n",
    "try:\n",
    "    # Initialize the library\n",
    "    ee.Initialize()\n",
    "    print('Google Earth Engine has initialized successfully!')\n",
    "except ee.EEException as e:\n",
    "    print('Google Earth Engine has failed to initialize!')\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select Turkey as the area of interest and create its bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.663, 35.817], [44.822, 35.817], [44.822, 42.366], [25.663, 42.366], [25.663, 35.817]]\n"
     ]
    }
   ],
   "source": [
    "# Bounding box of Turkey (Define the region of interest as a polygon,just need to define once here)\n",
    "left = 25.663\n",
    "right = 44.822\n",
    "up= 42.366\n",
    "down = 35.817 \n",
    "\n",
    "roi = ee.Geometry.Polygon(\n",
    "        [[[left, down],\n",
    "          [right, down],\n",
    "          [right, up],\n",
    "          [left, up],]], None, False)\n",
    "\n",
    "bbox = roi.bounds().getInfo()['coordinates'][0]\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we center Turkey at the center of the map and add the bounding box as a layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec17122c076f4eeca5b8a8ea873dafad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[39.091499999999996, 35.2425], controls=(WidgetControl(options=['position', 'transparent_bg'], widgâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a map centered on Turkey\n",
    "map = geemap.Map(center=[(up+down)/2, (left+right)/2], zoom=6)\n",
    "\n",
    "# Add the bounding box to the map\n",
    "bbox_layer = geemap.geojson_to_ee({\n",
    "    'type': 'Feature',\n",
    "    'geometry': {\n",
    "        'type': 'Polygon',\n",
    "        'coordinates': [bbox]\n",
    "    },\n",
    "    'properties': {\n",
    "        'name': 'Bounding box'\n",
    "    }\n",
    "})\n",
    "map.addLayer(bbox_layer, {'color': 'grey'}, 'Bounding box')\n",
    "\n",
    "# Display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add the reference points\n",
    "*Filter the reference points to the selected region of interest*\n",
    "\n",
    "- The reference points are stored in the multiple .csv file under /Reference_Point\n",
    "- We read them as DataFrame first and then convert it to ee FeatureCollection.\n",
    "\n",
    "NB! Task was solved with three solutions (A, B, C), each of which runs parallelly with the others. So you just need to run one of them for the whole assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Solution A\n",
    "- As Google Earth API cannot handle external data larger than 10Mb, so we need to avoid making a big complete ee FeatureColleciton of all points and handle it by ee package. Instead, we need to decrease the size of the ee FeatureCollection.\n",
    "- Therefore, here we read all the points into dataframe first and finishe the filtering when it was still a dataframe.\n",
    "- Then, we convert this smaller dataframe into ee FeatureCollection.\n",
    "- This method took 9.1 seconds to finish on my laptop locally. (We need Internet connection after the conversion from dataframe, like half the process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: Reference_Point/SamplesSet*.csv resolved to no files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dask/backends.py:136\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    137\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dask/dataframe/io/csv.py:763\u001b[0m, in \u001b[0;36mmake_reader.<locals>.read\u001b[0;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\n\u001b[1;32m    751\u001b[0m     urlpath,\n\u001b[1;32m    752\u001b[0m     blocksize\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    762\u001b[0m ):\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mreturn\u001b[39;00m read_pandas(\n\u001b[1;32m    764\u001b[0m         reader,\n\u001b[1;32m    765\u001b[0m         urlpath,\n\u001b[1;32m    766\u001b[0m         blocksize\u001b[39m=\u001b[39;49mblocksize,\n\u001b[1;32m    767\u001b[0m         lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m    768\u001b[0m         compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    769\u001b[0m         sample\u001b[39m=\u001b[39;49msample,\n\u001b[1;32m    770\u001b[0m         sample_rows\u001b[39m=\u001b[39;49msample_rows,\n\u001b[1;32m    771\u001b[0m         enforce\u001b[39m=\u001b[39;49menforce,\n\u001b[1;32m    772\u001b[0m         assume_missing\u001b[39m=\u001b[39;49massume_missing,\n\u001b[1;32m    773\u001b[0m         storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    774\u001b[0m         include_path_column\u001b[39m=\u001b[39;49minclude_path_column,\n\u001b[1;32m    775\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    776\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dask/dataframe/io/csv.py:535\u001b[0m, in \u001b[0;36mread_pandas\u001b[0;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(paths) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 535\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00murlpath\u001b[39m}\u001b[39;00m\u001b[39m resolved to no files\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    537\u001b[0m \u001b[39m# Infer compression from first path\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: Reference_Point/SamplesSet*.csv resolved to no files",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/yokosukamori/Library/CloudStorage/OneDrive-UniversityofTwente/Geo-Bigdata-Processing/GEE_K-means_Practice/Assignment.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yokosukamori/Library/CloudStorage/OneDrive-UniversityofTwente/Geo-Bigdata-Processing/GEE_K-means_Practice/Assignment.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yokosukamori/Library/CloudStorage/OneDrive-UniversityofTwente/Geo-Bigdata-Processing/GEE_K-means_Practice/Assignment.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Use DASK to read all csv together\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yokosukamori/Library/CloudStorage/OneDrive-UniversityofTwente/Geo-Bigdata-Processing/GEE_K-means_Practice/Assignment.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m da \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mReference_Point/SamplesSet*.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yokosukamori/Library/CloudStorage/OneDrive-UniversityofTwente/Geo-Bigdata-Processing/GEE_K-means_Practice/Assignment.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ref_point \u001b[39m=\u001b[39m da\u001b[39m.\u001b[39mcompute()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yokosukamori/Library/CloudStorage/OneDrive-UniversityofTwente/Geo-Bigdata-Processing/GEE_K-means_Practice/Assignment.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Get rid of the rows with no landcover\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/dask/backends.py:138\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    137\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(\n\u001b[1;32m    139\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling the \u001b[39m\u001b[39m{\u001b[39;00mfuncname(func)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmethod registered to the \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackend\u001b[39m}\u001b[39;00m\u001b[39m backend.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOriginal Message: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: Reference_Point/SamplesSet*.csv resolved to no files"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# Use DASK to read all csv together\n",
    "da = dd.read_csv('Reference_Point/SamplesSet*.csv')\n",
    "ref_point = da.compute()\n",
    "\n",
    "# Get rid of the rows with no landcover\n",
    "ref_point = ref_point.dropna(subset=['landcover'])\n",
    "\n",
    "# Filter the data withi the area of interest\n",
    "ref_point_sub = ref_point[(ref_point['lon'] >= left) & (ref_point['lon'] <= right) & (ref_point['lat'] >= down) & (ref_point['lat'] <= up)]\n",
    "\n",
    "print(ref_point_sub)\n",
    "\n",
    "# Convert the data to a ee feature\n",
    "def row_to_feature(row):\n",
    "    point = ee.Geometry.Point(row['lon'], row['lat'])\n",
    "    feature = ee.Feature(point, {'landcover': row['landcover']})\n",
    "    return feature\n",
    "\n",
    "# Make feature collection\n",
    "feature_list = ref_point_sub.apply(row_to_feature,axis=1).tolist()\n",
    "feature_collection = ee.FeatureCollection(feature_list)\n",
    "ref_point_ee = feature_collection.filter(ee.Filter.geometry(roi))\n",
    "print(ref_point_ee.size().getInfo())\n",
    "\n",
    "map.addLayer(ref_point_ee, {}, 'Area_of_Interest')\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Solution B\n",
    "NB. the solution also exceeds the 10Mb limit, so it is not the best solution.\n",
    "\n",
    "- Same reason for Solution A, Google Earth API cannot handle external data larger than 10Mb. Solution B tries to avoid online calculation with big dataset by making loops to handle the process separately. \n",
    "- Here the way could be loop around each csv file, convert it into ee FeatureCollection, filter it and then merge the selected point with the result of last loop.\n",
    "- This solution keeps calling Google Earth, therefore robust net connection for the whole process is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "# import pandas as pd\n",
    "\n",
    "# # Convert the data to a ee feature\n",
    "# def row_to_feature(row):\n",
    "#     point = ee.Geometry.Point(row['lon'], row['lat'])\n",
    "#     feature = ee.Feature(point, {'landcover': row['landcover']})\n",
    "#     return feature\n",
    "\n",
    "# ref_point= pd.DataFrame({})\n",
    "# ref_point_ee= ee.FeatureCollection([])\n",
    "# # loop each csv and run the process separately\n",
    "# for i in range(1,11):\n",
    "#     path= 'Reference_Point/SamplesSet'+ str(i) +'.csv'\n",
    "#     ref_point_sub = pd.read_csv(path)\n",
    "#     ref_point_sub = ref_point_sub.dropna(subset=['landcover'])\n",
    "#     # merge the dataframe\n",
    "#     ref_point = pd.concat([ref_point,ref_point_sub])\n",
    "#     # convert the dataframe to ee feature\n",
    "#     feature_list = ref_point_sub.apply(row_to_feature,axis=1).tolist()\n",
    "#     feature_collection = ee.FeatureCollection(feature_list)\n",
    "#     filtered_collection = feature_collection.filter(ee.Filter.geometry(roi))\n",
    "#     # merge the feature collection\n",
    "#     ref_point_ee = ref_point_ee.merge(filtered_collection)\n",
    "#     # print(ref_point_ee.size().getInfo())\n",
    "\n",
    "# ref_point\n",
    "# map.addLayer(ref_point_ee, {}, 'Area_of_Interest')\n",
    "# map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Solution C\n",
    "- Solution C avoids online calculating with big dataset by using geopandas to handle geo objects.\n",
    "- We could add the points as geodataframe and filter it with the area of interest locally with geopandas\n",
    "- And then we transfer the geodataframe into ee. objest. So the input for the geemap occupies a much smaller storage.\n",
    "- This soltion takes 6.9 seconds. It just needs Internet for the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# use DASK to read all csv together\n",
    "da = dd.read_csv('Reference_Point/SamplesSet*.csv')\n",
    "ref_point = da.compute()\n",
    "\n",
    "# Get rid of the rows with no landcover\n",
    "ref_point = ref_point.dropna(subset=['landcover'])\n",
    "\n",
    "# Convert the dataframe to geodataframe\n",
    "geometry = [Point(xy) for xy in zip(ref_point['lon'], ref_point['lat'])]\n",
    "gdf = gpd.GeoDataFrame(ref_point, geometry=geometry, crs='EPSG:4326')\n",
    "gdf = gdf.drop(['lon', 'lat'], axis=1)\n",
    "\n",
    "# Filter the points in the area of interest\n",
    "area_of_interest = Polygon([(left, down), (right, down), (right, up), (left, up)])\n",
    "gdf_ref_point_sub = gdf.cx[left:right, down:up]\n",
    "\n",
    "# Convert the geodataframe to ee\n",
    "ref_point_ee = geemap.geopandas_to_ee(gdf_ref_point_sub)\n",
    "\n",
    "# Add the points to the map\n",
    "map.addLayer(ref_point_ee, {}, 'Area_of_Interest')\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 & 4. Generate image collection & Calculate the median image \n",
    "- *Generate Sentinel 2 images for this region of interest covering the summer of 2023*\n",
    "- *Reduce this image collection by calculating the median of all values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mask clouds in Sentinel-2 image using QA band\n",
    "def mask_s2_clouds(image):\n",
    "  qa = image.select('QA60')\n",
    "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "  cloud_bit_mask = 1 << 10\n",
    "  cirrus_bit_mask = 1 << 11\n",
    "  # Both flags should be set to zero, indicating clear conditions.\n",
    "  mask = (\n",
    "      qa.bitwiseAnd(cloud_bit_mask)\n",
    "      .eq(0)\n",
    "      .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "  )\n",
    "  # Return the image after the mask is applied and divide it by 10000 to scale the values around 0-1 \n",
    "  return image.updateMask(mask).divide(10000)\n",
    "\n",
    "# Get the Sentinel-2 image collection for the region of interest\n",
    "image = (\n",
    "     ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \n",
    "    .filterBounds(roi) \n",
    "    # Summer 2023\n",
    "    .filterDate('2023-06-01', '2023-08-31') \n",
    "    # Pre-filter to get less cloudy granules.\n",
    "    .filterMetadata('CLOUDY_PIXEL_PERCENTAGE', 'less_than', 10) \n",
    "    .map(mask_s2_clouds)\n",
    "    # Get the median of the image collection\n",
    "    .median()\n",
    ")\n",
    "\n",
    "# Set visualization parameters for visulization\n",
    "vis_params = {\n",
    "    'min': 0,'max': 0.4,\n",
    "    'bands': [\"B4\", \"B3\", \"B2\"]\n",
    "}\n",
    "\n",
    "map.addLayer(image, vis_params, 'S2-2019-Median')\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize the reference points and image\n",
    "*Make the image and visualisation together on one map*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 'Bounding box' layer and hide it\n",
    "bbox_layer = map.find_layer('Bounding box')\n",
    "bbox_layer.visible = False\n",
    "\n",
    "# Add the reference points to the map\n",
    "map.addLayer(ref_point_ee, {}, 'Area_of_Interest')\n",
    "map\n",
    "\n",
    "# Set visualization parameters for visulization of image\n",
    "vis_params = {\n",
    "    'min': 0,'max': 0.4,\n",
    "    'bands': [\"B4\", \"B3\", \"B2\"]\n",
    "}\n",
    "# Add the image to the map\n",
    "map.addLayer(image, vis_params, 'S2-2019-Median')\n",
    "map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make cluster\n",
    "- *Cluster the selected image into a predefined number of clusters*\n",
    "- *You can use the reference points labels to get a first estimation of number of clusters and k-mean as the clustering algorithm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the sample points to train the K-means model\n",
    "training = image.sample(**{\n",
    "    'scale': 30,\n",
    "    # 8000 points in total\n",
    "    'numPixels': 8000,\n",
    "    'seed': 0,\n",
    "    'geometries': True, \n",
    "    'region': roi,\n",
    "    # set the tilescan to reduce the occupancy of the storage\n",
    "    'tileScale': 4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the cluster number as 5 (the reference points have 5 types of landcover)\n",
    "cluster_number = 5\n",
    "clusterer = ee.Clusterer.wekaKMeans(cluster_number).train(training)\n",
    "\n",
    "# Cluster the input using the trained clusterer.\n",
    "image_clustered = image.cluster(clusterer)\n",
    "\n",
    "# Display the clusters with random colors.\n",
    "map.addLayer(image_clustered.randomVisualizer(), {}, 'clusters')\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Analyze the clustering results. \n",
    "For example, you can use histogram of the land cover classes per cluster id generated by the k-means algorithm.\n",
    "\n",
    "- Per Cluster ID, we visualised the distribution of different land cover groups (x-axis is different cluster, y-axis is number of reference points of this land cover on the cluster)\n",
    "- We also calculted the V-measure index (a comprehensive index evaluating the homogeneity in one cluster and the completeness from different clusters) to quantify the quality of the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the value of clustered image (cluster_id) into reference point\n",
    "joined_ref_point_ee = image_clustered.reduceRegions(\n",
    "    collection=ref_point_ee,\n",
    "    reducer=ee.Reducer.mean(),\n",
    "    crs='EPSG:4326',\n",
    "    scale = 30,\n",
    "    tileScale = 4\n",
    ")\n",
    "\n",
    "print(joined_ref_point_ee.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the reference point with joined cluster_id into dataframe\n",
    "joined_ref_point= geemap.ee_to_pandas(joined_ref_point_ee)\n",
    "# Rename the columns of cluster_id to make it more readable\n",
    "joined_ref_point = joined_ref_point.rename(columns={\"mean\": \"cluster_id\"})\n",
    "joined_ref_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# reshape the dataframe to pivot-table (to calculate the number of different land covers per cluster id)\n",
    "pivot_table = joined_ref_point.pivot_table(index=\"landcover\", columns=\"cluster_id\", values=None, aggfunc=\"size\")\n",
    "\n",
    "# build up the sub plots\n",
    "fig, axs = plt.subplots(ncols=1, nrows=len(pivot_table.columns), figsize=(9, 25))\n",
    "\n",
    "# to visualise the charts\n",
    "for i, column in enumerate(pivot_table.columns):\n",
    "    axs[i].bar(pivot_table.index, pivot_table[column])\n",
    "    axs[i].set_xlabel(\"cluster_id: \"+str(column))\n",
    "    axs[i].set_ylabel(\"landcover count\")\n",
    "    #axs[i].set_title(column)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import v_measure_score\n",
    "\n",
    "#to calculate the v-measure for the clustering (range of v-measure is 0-1, 1 stands for better interpretation of real situation )\n",
    "v_measure = v_measure_score(joined_ref_point['landcover'], joined_ref_point['cluster_id'])\n",
    "print(\"V-measure: \", v_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Change the number of clusters and repeat the analysis\n",
    "- For Point of Dicussion 2, we run the code with different number of clusters, get the V-measure index and compare (also compare time)\n",
    "- For Point of Dicussion 3, we run the training in a smaller/similar area similar with less/same land cover types first. Then apply it to our Turkey and compare the V-measure index. (also compare time)\n",
    "- For Point of Dicussion 4, we first record time in Solution A,B,C at chapter 2. Then we also record time for different number of clusters and applying model to Turkey with different training models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points of Discussions\n",
    "\n",
    "- Why do we need to train an unsupervised classifier in GEE?\n",
    "- Impact of the number clusters on the results\n",
    "- Impact of performing the clustering in region X and applying it on region Y\n",
    "  - Region Y has the same land cover classes present in Region X\n",
    "  - Region Y has more land cover classes/types.\n",
    "- What can you say about the computational time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
